{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../utils')\n",
    "import fvdb\n",
    "import fvdb_utils\n",
    "import mesh_tools as mt\n",
    "import igl\n",
    "import numpy as np\n",
    "from ssfid import calculate_activation_statistics, calculate_frechet_distance\n",
    "from patch_utils import pairwise_IoU_dist\n",
    "from classifier3D import classifier\n",
    "import torch\n",
    "import os\n",
    "import glob\n",
    "from tqdm import tqdm\n",
    "import trimesh \n",
    "\n",
    "device='cuda'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "voxel_size = 256\n",
    "model = classifier(voxel_size=voxel_size)\n",
    "\n",
    "weights_path = 'Clsshapenet_'+str(voxel_size)+'.pth'\n",
    "if not os.path.exists(weights_path):\n",
    "    raise RuntimeError(\n",
    "        f\"'{weights_path}' not exists. Please download it from https://drive.google.com/file/d/1HjnDudrXsNY4CYhIGhH4Q0r3-NBnBaiC/view?usp=sharing.\")\n",
    "model.load_state_dict(torch.load(weights_path, weights_only=False))\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "names = os.listdir(\"../../data/GT_WT\")\n",
    "names.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_grid_points_aabb(aabb, resolution):\n",
    "    aabb_min, aabb_max = aabb[:3], aabb[3:]\n",
    "    aabb_size = aabb_max - aabb_min\n",
    "    resolutions = (resolution * aabb_size / aabb_size.max()).astype(np.int32)\n",
    "\n",
    "    xs = np.linspace(0.5, resolutions[0] - 0.5, resolutions[0]) / resolutions[0] * aabb_size[0] + aabb_min[0]\n",
    "    ys = np.linspace(0.5, resolutions[1] - 0.5, resolutions[1]) / resolutions[1] * aabb_size[1] + aabb_min[1]\n",
    "    zs = np.linspace(0.5, resolutions[2] - 0.5, resolutions[2]) / resolutions[2] * aabb_size[2] + aabb_min[2]\n",
    "    grid_points = np.stack(np.meshgrid(xs, ys, zs, indexing='ij'), axis=-1)\n",
    "    return grid_points\n",
    "\n",
    "def normalize_aabb(v, reso, enlarge_scale=1.03, mult=8):\n",
    "    aabb_min = np.min(v, axis=0)\n",
    "    aabb_max = np.max(v, axis=0)\n",
    "    center = (aabb_max + aabb_min) / 2\n",
    "    bbox_size = (aabb_max - aabb_min).max() * enlarge_scale\n",
    "    translation = -center\n",
    "    scale = 1.0 / bbox_size * 2\n",
    "    # v = (v + translation) * scale\n",
    "    # v = (v - center) / bbox_size * 2\n",
    "    aabb_min = (aabb_min * enlarge_scale - center) / bbox_size * 2\n",
    "    aabb_max = (aabb_max * enlarge_scale - center) / bbox_size * 2\n",
    "    aabb = np.concatenate([aabb_min, aabb_max], axis=0)\n",
    "    aabb_size = aabb_max - aabb_min\n",
    "    fm_size = (reso * aabb_size / aabb_size.max()).astype(np.int32)\n",
    "    # round to multiple of 8\n",
    "    fm_size = (fm_size + mult - 1) // mult * mult\n",
    "    aabb_max = fm_size / fm_size.max()\n",
    "    aabb = np.concatenate([-aabb_max, aabb_max], axis=0)\n",
    "    return aabb, translation, scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dense_array_tight(shape_path, pts=None, translation=None, scale=None):\n",
    "    ms = trimesh.load(shape_path)\n",
    "    v = ms.vertices\n",
    "    f = ms.faces\n",
    "    # v, f = igl.read_triangle_mesh(shape_path)\n",
    "    if pts is None:\n",
    "        out_grid = True\n",
    "        v = 2*mt.NDCnormalize(v)\n",
    "        aabb, translation, scale = normalize_aabb(v, 256)\n",
    "        v = (v+translation)*scale\n",
    "        pts = sample_grid_points_aabb(aabb, 256)\n",
    "\n",
    "    else:\n",
    "        out_grid = False\n",
    "        v = (v+translation)*scale\n",
    "        \n",
    "    sdf_compute = igl.fast_winding_number_for_meshes(v, f, pts.reshape(-1, 3))>.5\n",
    "    or_sdfgrid = sdf_compute.reshape(pts.shape[:-1])\n",
    "    new_shape = [int(x * voxel_size / max(or_sdfgrid.shape))\n",
    "                        for x in or_sdfgrid.shape]\n",
    "\n",
    "    or_sdfgrid = torch.nn.functional.adaptive_max_pool3d(1.*torch.tensor(or_sdfgrid[None, None], device=device), new_shape)[0, 0]>0\n",
    "    or_sdfgrid = 1.*or_sdfgrid\n",
    "    if out_grid:\n",
    "        return or_sdfgrid, pts, translation, scale\n",
    "    return or_sdfgrid\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_metrics(globe, mesh_name):\n",
    "    shapes = glob.glob(globe.format(mesh_name))\n",
    "    shapes.sort()\n",
    "    # print(shapes)\n",
    "    or_sdfgrid, pts, translation, scale = get_dense_array_tight(\"../../data/GT_WT/{}.obj\".format(mesh_name))\n",
    "    mu_r, sigma_r = calculate_activation_statistics(or_sdfgrid, model)\n",
    "    ssfid_values = []\n",
    "    grids = []\n",
    "    for shape in shapes:\n",
    "        dense_grid = get_dense_array_tight(shape, pts, translation, scale)\n",
    "        mu_f, sigma_f = calculate_activation_statistics(dense_grid, model)\n",
    "        ssfid = calculate_frechet_distance(mu_r, sigma_r, mu_f, sigma_f)\n",
    "        print(ssfid)\n",
    "        ssfid_values.append(ssfid)\n",
    "        grids.append(dense_grid)\n",
    "    return np.mean(ssfid_values).round(4), pairwise_IoU_dist(torch.stack(grids, dim=0)).round(4)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = [e[:-4] for e in os.listdir('../../data/GT_WT')]\n",
    "names.sort()\n",
    "str_path = '../../meshed_output/{}/**/large_mesh.ply'\n",
    "\n",
    "ours_ssfid = []\n",
    "ours_iou = []\n",
    "for name in tqdm(names):\n",
    "    ssfid, io = get_metrics(str_path, name)\n",
    "    ours_ssfid.append(ssfid)\n",
    "    ours_iou.append(io)\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ssfid_data = ours_ssfid + [np.array(ours_ssfid).mean()]\n",
    "iou_data = ours_iou + [np.array(ours_iou).mean()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ssfid_data = ours_ssfid + [np.array(ours_ssfid).mean()]\n",
    "iou_data = ours_iou + [np.array(ours_iou).mean()]\n",
    "print(r\"\\begin{tabular}{ l |c| \" +\"\".join([' c ' for e in names]) + r\" | c }\")\n",
    "\n",
    "print(r'Metric & Method               & {} & mean \\\\'.format(' & '.join(names)))\n",
    "print(r'\\hline')\n",
    "print(r'G-Qual. $\\downarrow$ & ours & {}\\\\'.format('   &    '.join(['{:.2f}' for e in ssfid_data]).format(*ssfid_data)))\n",
    "print(r'\\hline') \n",
    "print(r'G-Div. $\\uparrow$ & ours    & {}\\\\'.format('   &    '.join(['{:.2f}' for e in iou_data]).format(*iou_data)))\n",
    "print(r\"\\end{tabular}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fvdb_test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
