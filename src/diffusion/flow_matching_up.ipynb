{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('/home/nmaruani/ShapeShifter')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.diffusion.train_flow_matching import *\n",
    "import yaml\n",
    "from IPython.display import clear_output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "level=1\n",
    "model_name=\"canyon\"\n",
    "with open(f'/home/nmaruani/ShapeShifter/configs/train_diffusion_up.yaml', 'r') as f:\n",
    "    cfg = yaml.load(f, Loader=yaml.Loader)\n",
    "\n",
    "X, X_UP, X0 = get_gt_data(cfg, level, model_name)\n",
    "device='cuda'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_upsampler = torch.load(\n",
    "            './checkpoints/upsamplers_colors/{}_{}.pt'.format(model_name, level), weights_only=False)\n",
    "\n",
    "model_upsampler.eval()\n",
    "with torch.no_grad():\n",
    "    X0_BLUR = model_upsampler(X, X_UP).detach()\n",
    "X0_BLUR.grid = X0.grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has 1.2M parameters\n"
     ]
    }
   ],
   "source": [
    "L = []\n",
    "LOSS_EMA = None\n",
    "model = DiffusionCNN(channels=cfg[\"features\"], layers=cfg[\"layers\"], time_emb=cfg[\"time_emb\"],\n",
    "                        one_layers=cfg[\"one_layers\"], first_ks=cfg[\"first_ks\"],\n",
    "                        in_channels=X0.jdata.shape[-1], out_channels=X0.jdata.shape[-1]).to(device)\n",
    "mt.count_parameters(model)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(),\n",
    "                                lr=cfg[\"lr\"]\n",
    "                                )\n",
    "\n",
    "loss_fn = torch.nn.functional.mse_loss\n",
    "sparse_fm = SparseFlowMatching(\n",
    "        model,\n",
    "        timesteps=cfg[\"diffusion_timesteps\"],\n",
    "        loss=nn.functional.mse_loss,\n",
    "        model_upsampler=model_upsampler if level > 0 else None,\n",
    "    ).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(optimizer, sparse_fm):\n",
    "        global LOSS_EMA\n",
    "        optimizer.zero_grad()\n",
    "        if level > 0:\n",
    "            loss = sparse_fm(*clip_data(X0, X0_BLUR, cfg[\"clip_size\"]))\n",
    "        else:\n",
    "            loss = sparse_fm(X0)\n",
    "        torch.nn.utils.clip_grad_norm_(sparse_fm.model.parameters(), 1.)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if LOSS_EMA is None:\n",
    "            LOSS_EMA = loss.item()\n",
    "        else:\n",
    "            LOSS_EMA = 0.99 * LOSS_EMA + 0.01 * loss.item()\n",
    "        L.append(LOSS_EMA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 163/40000 [00:05<23:11, 28.62it/s] \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m model\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28mrange\u001b[39m(cfg[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mepochs\u001b[39m\u001b[38;5;124m\"\u001b[39m])):\n\u001b[0;32m----> 3\u001b[0m     \u001b[43mtrain_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msparse_fm\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m%\u001b[39m cfg[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msave_every\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m i \u001b[38;5;241m==\u001b[39m cfg[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mepochs\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m      5\u001b[0m         clear_output(\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "Cell \u001b[0;32mIn[11], line 5\u001b[0m, in \u001b[0;36mtrain_epoch\u001b[0;34m(optimizer, sparse_fm)\u001b[0m\n\u001b[1;32m      3\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m level \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m----> 5\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[43msparse_fm\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mclip_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX0_BLUR\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mclip_size\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m      7\u001b[0m     loss \u001b[38;5;241m=\u001b[39m sparse_fm(X0)\n",
      "File \u001b[0;32m~/anaconda3/envs/fvdb_test/lib/python3.10/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/fvdb_test/lib/python3.10/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/ShapeShifter/src/diffusion/train_flow_matching.py:82\u001b[0m, in \u001b[0;36mSparseFlowMatching.forward\u001b[0;34m(self, X0, X0_BLUR)\u001b[0m\n\u001b[1;32m     80\u001b[0m x_t \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m t) \u001b[38;5;241m*\u001b[39m x_0 \u001b[38;5;241m+\u001b[39m t \u001b[38;5;241m*\u001b[39m x_1\n\u001b[1;32m     81\u001b[0m XT \u001b[38;5;241m=\u001b[39m fvnn\u001b[38;5;241m.\u001b[39mVDBTensor(grid\u001b[38;5;241m=\u001b[39mX0\u001b[38;5;241m.\u001b[39mgrid, feature\u001b[38;5;241m=\u001b[39mX0\u001b[38;5;241m.\u001b[39mgrid\u001b[38;5;241m.\u001b[39mjagged_like(x_t))\n\u001b[0;32m---> 82\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mXT\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflatten\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mjdata, x_1)\n",
      "File \u001b[0;32m~/anaconda3/envs/fvdb_test/lib/python3.10/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/fvdb_test/lib/python3.10/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/ShapeShifter/./src/utils/model.py:43\u001b[0m, in \u001b[0;36mDiffusionCNN.forward\u001b[0;34m(self, x, t, cond)\u001b[0m\n\u001b[1;32m     40\u001b[0m t \u001b[38;5;241m=\u001b[39m sinusoidal_embedding(t, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtime_emb)\n\u001b[1;32m     41\u001b[0m new_x \u001b[38;5;241m=\u001b[39m fvnn\u001b[38;5;241m.\u001b[39mVDBTensor(x\u001b[38;5;241m.\u001b[39mgrid, x\u001b[38;5;241m.\u001b[39mgrid\u001b[38;5;241m.\u001b[39mjagged_like(\n\u001b[1;32m     42\u001b[0m     torch\u001b[38;5;241m.\u001b[39mcat((x\u001b[38;5;241m.\u001b[39mfeature\u001b[38;5;241m.\u001b[39mjdata, t), \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)))\n\u001b[0;32m---> 43\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnet\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnew_x\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/fvdb_test/lib/python3.10/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/fvdb_test/lib/python3.10/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/fvdb_test/lib/python3.10/site-packages/torch/nn/modules/container.py:219\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    217\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 219\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    220\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/envs/fvdb_test/lib/python3.10/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/fvdb_test/lib/python3.10/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/fvdb_test/lib/python3.10/site-packages/fvdb/nn/modules.py:23\u001b[0m, in \u001b[0;36mfvnn_module.<locals>._forward\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_forward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     22\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m record_function(\u001b[38;5;28mrepr\u001b[39m(\u001b[38;5;28mself\u001b[39m)):\n\u001b[0;32m---> 23\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mold_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/fvdb_test/lib/python3.10/site-packages/fvdb/nn/modules.py:381\u001b[0m, in \u001b[0;36mSparseConv3d.forward\u001b[0;34m(self, input, out_grid)\u001b[0m\n\u001b[1;32m    378\u001b[0m     out_grid, out_kmap \u001b[38;5;241m=\u001b[39m in_grid, in_kmap\n\u001b[1;32m    380\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 381\u001b[0m     out_grid, out_feature, out_kmap \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dispatch_conv\u001b[49m\u001b[43m(\u001b[49m\u001b[43min_feature\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43min_grid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43min_kmap\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout_grid\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    383\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    384\u001b[0m     out_feature\u001b[38;5;241m.\u001b[39mjdata \u001b[38;5;241m=\u001b[39m out_feature\u001b[38;5;241m.\u001b[39mjdata \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias\n",
      "File \u001b[0;32m~/anaconda3/envs/fvdb_test/lib/python3.10/site-packages/fvdb/nn/modules.py:328\u001b[0m, in \u001b[0;36mSparseConv3d._dispatch_conv\u001b[0;34m(self, in_feature, in_grid, in_kmap, out_grid)\u001b[0m\n\u001b[1;32m    325\u001b[0m backend \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_kmap_and_convert_backend(kmap, backend)\n\u001b[1;32m    327\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransposed:\n\u001b[0;32m--> 328\u001b[0m     out_feature \u001b[38;5;241m=\u001b[39m \u001b[43mkmap\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msparse_conv_3d\u001b[49m\u001b[43m(\u001b[49m\u001b[43min_feature\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbackend\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    329\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    330\u001b[0m     out_feature \u001b[38;5;241m=\u001b[39m kmap\u001b[38;5;241m.\u001b[39msparse_transpose_conv_3d(in_feature, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight, backend)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.train()\n",
    "for i in tqdm(range(cfg[\"epochs\"])):\n",
    "    train_epoch(optimizer, sparse_fm)\n",
    "    if i % cfg[\"save_every\"] == 0 or i == cfg[\"epochs\"]-1:\n",
    "        clear_output(True)\n",
    "        plt.plot(L, label='canyon')\n",
    "        plt.yscale('log')\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "torch.save(model, f'fm_{model_name}_{level}.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sampling+"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def p1_to_flow(model, XT, T):\n",
    "    p1 = model(XT, T)\n",
    "    p1.feature.jdata = (p1.jdata-XT.jdata)/(1-T[:, None])\n",
    "    return p1\n",
    "    \n",
    "@torch.no_grad()\n",
    "def model_step(model, XT, t_start, t_end):\n",
    "    TSTART = t_start.view(1).expand(len(XT.jdata))\n",
    "    TEND = t_end.view(1).expand(len(XT.jdata))\n",
    "\n",
    "    p1 = p1_to_flow(model, XT, TSTART)\n",
    "    p1.feature.jdata *= (TEND-TSTART)[:, None]/2.\n",
    "    p1.feature.jdata += XT.jdata\n",
    "    \n",
    "    \n",
    "    p2 = p1_to_flow(model, p1, TSTART+ (TEND-TSTART)/2.)\n",
    "    \n",
    "    p2.feature.jdata *= (TEND-TSTART)[:, None]\n",
    "    p2.feature.jdata += XT.jdata\n",
    "    \n",
    "    return p2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2961817/2254865755.py:5: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model = torch.load(f'fm_{model_name}_{level}.pt')\n",
      "100%|██████████| 200/200 [00:01<00:00, 105.42it/s]\n"
     ]
    }
   ],
   "source": [
    "i=0\n",
    "fac = .8\n",
    "n_steps = 200\n",
    "time_steps = torch.linspace(0, 1.0, n_steps + 1, device=device)\n",
    "model = torch.load(f'fm_{model_name}_{level}.pt')\n",
    "model.eval()\n",
    "X = fvnn.VDBTensor(grid=X0.grid, feature=X0.grid.jagged_like(torch.randn_like(X0.jdata)))\n",
    "X.feature.jdata = (fac)*X0_BLUR.jdata + (1-fac)*torch.randn_like(X0.jdata)\n",
    "X0data = X.jdata.clone()\n",
    "for i in tqdm(range(n_steps-1)):\n",
    "    X = model_step(model, X, time_steps[i], time_steps[i+1])\n",
    "X = model(X, time_steps[-2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8a97a5bd5954cccadcf013e5fa8d62f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Renderer(camera=PerspectiveCamera(children=(DirectionalLight(color='white', intensity=0.6, position=(0.0, 0.0,…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b379853370c64b9ba7dc83cf6a2ae1d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Renderer(camera=PerspectiveCamera(children=(DirectionalLight(color='white', intensity=0.6, position=(0.0, 0.0,…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for ind in range(2):\n",
    "    disp_d = DiffusionTensor(X.grid[ind], X.feature[ind]).remove_mask()\n",
    "    # disp_d.get_global().colored_PC(.07)\n",
    "\n",
    "    c=(disp_d.feature.jdata[:, 6:9].cpu().detach().numpy()+2)/4\n",
    "    plot(*grid_to_mesh(disp_d.grid, colors=c), shading={'wireframe':True})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fvdb_test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
